---
title: "Salmonella model training"
author: "Nicole Wheeler"
date: "10/6/2016"
output: html_document
---

This is the complete workflow used to generate a random forest model using output data from an hmmsearch of your protein coding genes against eggNOG gamma proteobacterial protein HMMs. 

To replicate this analysis, you will need to get your own hmmsearch domain table output files for each proteome of interest, be able to classify each strain by their phenotype, and have a table of orthologous genes for your strains of interest. 

Before running this notebook, run the parse_hmmsearch.pl script to get a tab-delimited file containing bitscores for all orthogroups. 

```{r}
library(gplots)
library(caret)
library(randomForest)
set.seed(1)

eggNOG <- read.delim("eggNOGscores.tsv", header=F)
check <- read.delim("checkmodels", header=F)
inconsistent <- vector()
for(i in 1:nrow(check)) {
  if(length(unique(check[i,][!is.na(check[i,])]))==1) {
    inconsistent <- c(inconsistent, FALSE)
  } else {
    inconsistent <- c(inconsistent, TRUE)
  }
}
eggNOG <- eggNOG[!inconsistent,]

for(i in 2:ncol(eggNOG)) {
  eggNOG[is.na(eggNOG[,i]),i] <- 0
}
row.names(eggNOG) <- make.names(eggNOG[,1], unique=T)
eggNOG <- eggNOG[,-1]
eggNOG <- eggNOG[,-c(9,11)] # remove duplicate strains
eggNOG <- t(eggNOG)
row.names(eggNOG) <- c("Typhimurium", "Newport", "Heidelberg", "Schwarzengrund", "Agona", "Enteritidis", "ParatyphiB", "Typhi", "ParatyphiA", "Dublin", "Gallinarum", "Choleraesuis", "ParatyphiC")

eggNOG2 <- data.frame()
for (i in 1:ncol(eggNOG)) {
	eggNOG2 <- rbind(eggNOG2, median(eggNOG[,i], na.rm=T)-eggNOG[,i])
}

row.names(eggNOG2) <- colnames(eggNOG)
colnames(eggNOG2) <- c("Typhimurium", "Newport", "Heidelberg", "Schwarzengrund", "Agona", "Enteritidis", "ParatyphiB", "Typhi", "ParatyphiA", "Dublin", "Gallinarum", "Choleraesuis", "ParatyphiC")

traineggNOG <- eggNOG
traineggNOG <- traineggNOG[,-nearZeroVar(traineggNOG)]
traineggNOG <- cbind.data.frame(traineggNOG, c(rep("Gastro", 7), rep("Invasive", 6)))
colnames(traineggNOG)[ncol(traineggNOG)] = "class"


# save(traineggNOG, eggNOG, eggNOG2, file="model_data.Rdata")

# load("model_data.Rdata")  # for re-running analyses, you can skip to reading in the saved training data
```


```{r, train model}
# this section is for picking out the best parameters for building your model
set.seed(1)

# varying ntree
error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) { 
  model <- randomForest(class ~ ., data=traineggNOG, ntree=i, na.action=na.roughfix)
  error <- c(error, model$err.rate[length(model$err.rate)])
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(traineggNOG)-1))
}

# varying mtry
error2 <- vector()
sparsity2 <- vector()
param <- ncol(traineggNOG)-1
for(i in c(1, round(param/10), round(param/5), round(param/3), round(param/2), param)) {
  model <- randomForest(class ~ ., data=traineggNOG, ntree=10000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, model$err.rate[length(model$err.rate)])
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(traineggNOG)-1))
}

model <- randomForest(class ~ ., data=traineggNOG, ntree=10000, mtry=param/10, na.action=na.roughfix)

png("model_training/m1_error_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error, xlab="Number of trees", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m1_sparsity_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=sparsity, xlab="Number of trees", ylab="% genes uninformative", pch=16)
dev.off()
png("model_training/m1_error_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=error2, xlab="Number of genes sampled per tree", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m1_sparsity_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=sparsity2, xlab="Number of genes sampled per tree", ylab="% genes uninformative", pch=16)
dev.off()

train2 <- traineggNOG[,match(names(model$importance[model$importance[,1]>0,]), colnames(traineggNOG))]
train2 <- cbind(train2, class=traineggNOG$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=train2, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(train2)-1))
}

error2 <- vector()
sparsity2 <- vector()
param <- ncol(train2)-1
for(i in c(1, round(param/10), round(param/5), round(param/3), round(param/2), param)) {
  model <- randomForest(class ~ ., data=train2, ntree=10000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(train2)-1))
}

model <- randomForest(class ~ ., data=train2, ntree=10000, mtry=param/10, na.action=na.roughfix)

png("model_training/m2_error_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error, xlab="Number of trees", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m2_sparsity_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=sparsity, xlab="Number of trees", ylab="% genes uninformative", pch=16)
dev.off()
png("model_training/m2_error_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=error2, xlab="Number of genes sampled per tree", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m2_sparsity_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=sparsity2, xlab="Number of genes sampled per tree", ylab="% genes uninformative", pch=16)
dev.off()

train3 <- train2[,match(names(model$importance[model$importance[,1]>quantile(model$importance[,1], 0.5),]), colnames(train2))]
train3 <- cbind(train3, class=train2$class)

error <- vector()
sparsity <- vector()
param <- ncol(train3)-1
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=train3, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(train3)-1))
}

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, round(param/10), round(param/5), round(param/3), round(param/2), param)) {
  model <- randomForest(class ~ ., data=train3, ntree=10000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(train3)-1))
}

model <- randomForest(class ~ ., data=train3, ntree=10000, mtry=param/10, na.action=na.roughfix)

png("model_training/m3_error_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error, xlab="Number of trees", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m3_sparsity_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=sparsity, xlab="Number of trees", ylab="% genes uninformative", pch=16)
dev.off()
png("model_training/m3_error_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=error2, xlab="Number of genes sampled per tree", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m3_sparsity_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=sparsity2, xlab="Number of genes sampled per tree", ylab="% genes uninformative", pch=16)
dev.off()

train4 <- train3[,match(names(model$importance[model$importance[,1]>quantile(model$importance[,1], 0.5),]), colnames(train3))]
train4 <- cbind(train4, class=train3$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=train4, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(train4)-1))
}

error2 <- vector()
sparsity2 <- vector()
param <- ncol(train4)-1
for(i in c(1, round(param/10), round(param/5), round(param/3), round(param/2), param)) {
  model <- randomForest(class ~ ., data=train4, ntree=10000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(train4)-1))
}

model <- randomForest(class ~ ., data=train4, ntree=10000, mtry=param/10, na.action=na.roughfix)

png("model_training/m4_error_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error, xlab="Number of trees", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m4_sparsity_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=sparsity, xlab="Number of trees", ylab="% genes uninformative", pch=16)
dev.off()
png("model_training/m4_error_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=error2, xlab="Number of genes sampled per tree", ylab="OOB error rate", pch=16)
dev.off()
png("model_training/m4_sparsity_vs_mtry.png", width=350, height = 350)
plot(x=c(1, round(param/10), round(param/5), round(param/3), round(param/2), param), y=sparsity2, xlab="Number of genes sampled per tree", ylab="% genes uninformative", pch=16)
dev.off()

model$predicted

names(model$importance[order(model$importance, decreasing=T),][1:10])

```

```{r, quicker model building}
set.seed(1)
param <- ncol(traineggNOG)-1
model1 <- randomForest(class ~ ., data=traineggNOG, ntree=10000, mtry=param/10, na.action=na.roughfix)
model1

png("VI_full.png", width=400, height=350)
plot(1:param, model1$importance[order(model1$importance, decreasing=T)], xlim=c(1,1000), ylab="Variable importance", xlab="Top genes")
dev.off()
pdf("VI_full.pdf", width=5, height=5)
plot(1:param, model1$importance[order(model1$importance, decreasing=T)], xlim=c(1,1000), ylab="Variable importance", xlab="Top genes")
dev.off()

train2 <- traineggNOG[,match(names(model1$importance[model1$importance[,1]>0,]), colnames(traineggNOG))]
train2 <- cbind(train2, class=traineggNOG$class)
param <- ncol(train2)-1
model2 <- randomForest(class ~ ., data=train2, ntree=10000, mtry=param/10, na.action=na.roughfix)
model2

train3 <- train2[,match(names(model2$importance[model2$importance[,1]>quantile(model2$importance[,1], 0.5),]), colnames(train2))]
train3 <- cbind(train3, class=train2$class)
param <- ncol(train3)-1
model3 <- randomForest(class ~ ., data=train3, ntree=10000, mtry=param/10, na.action=na.roughfix)
model3

train4 <- train3[,match(names(model3$importance[model3$importance[,1]>quantile(model3$importance[,1], 0.5),]), colnames(train3))]
train4 <- cbind(train4, class=train3$class)
param <- ncol(train4)-1
model4 <- randomForest(class ~ ., data=train4, ntree=10000, mtry=param/10, na.action=na.roughfix)
model4

train5 <- train4[,match(names(model4$importance[model4$importance[,1]>quantile(model4$importance[,1], 0.5),]), colnames(train4))]
train5 <- cbind(train5, class=train4$class)
param <- ncol(train5)-1
model5 <- randomForest(class ~ ., data=train5, ntree=10000, mtry=param/10, na.action=na.roughfix)
model5

model5$predicted

names(train5)

png("final_model_VI.png", width=400, height=350)
plot(1:param, model5$importance[order(model5$importance, decreasing=T),], xlab="", ylab="Variable importance")
dev.off()

save(model1, model2, model3, model4, model5, traineggNOG, train2, train3, train4, train5, file="finalmodel.Rdata")
load("finalmodel.Rdata")
```

```{r, looking at votes}
votedata <- rbind.data.frame(cbind.data.frame(model=rep("1", 13), Serovar=row.names(model1$votes), Invasive=model1$votes[,2]), cbind.data.frame(model=rep("2", 13), Serovar=row.names(model1$votes), Invasive=model2$votes[,2]), cbind.data.frame(model=rep("3", 13), Serovar=row.names(model1$votes), Invasive=model3$votes[,2]), cbind.data.frame(model=rep("4", 13), Serovar=row.names(model1$votes), Invasive=model4$votes[,2]), cbind.data.frame(model=rep("5", 13), Serovar=row.names(model1$votes), Invasive=model5$votes[,2]))

ggplot(votedata, aes(x=model, y=Invasive, col=factor(Serovar, levels=row.names(model1$votes)))) + geom_jitter(width=0.1) + scale_color_manual("Serovar", values=c("#023858", "#045a8d", "#0570b0", "#3690c0", "#74a9cf", "#a6bddb", "#d0d1e6", "#fc9272", "#fb6a4a", "#ef3b2c", "#cb181d", "#a50f15", "#67000d")) + theme_classic(8) + ylab("Proportion of votes for invasive phenotype") + xlab("Model iteration") + geom_hline(yintercept=0.5, lty=2, col="grey") + theme(legend.key.size = unit(0.3, "cm"))
ggsave("votes.png", width=7, height=2.5)
ggsave("votes.pdf", width=7, height=2.5)

fullvotes <- rbind.data.frame(cbind.data.frame(model=rep("1", 13), Serovar=row.names(model1$votes), Invasive=predict(model1, traineggNOG, type="vote")[,2]), cbind.data.frame(model=rep("2", 13), Serovar=row.names(model1$votes), Invasive=predict(model2, train2, type="vote")[,2]), cbind.data.frame(model=rep("3", 13), Serovar=row.names(model1$votes), Invasive=predict(model3, train3, type="vote")[,2]), cbind.data.frame(model=rep("4", 13), Serovar=row.names(model1$votes), Invasive=predict(model4, train4, type="vote")[,2]), cbind.data.frame(model=rep("5", 13), Serovar=row.names(model1$votes), Invasive=predict(model5, train5, type="vote")[,2]))

ggplot(fullvotes, aes(x=model, y=Invasive, col=factor(Serovar, levels=row.names(model1$votes)))) + geom_jitter(width=0.1) + scale_color_manual("Serovar", values=c("#023858", "#045a8d", "#0570b0", "#3690c0", "#74a9cf", "#a6bddb", "#d0d1e6", "#fc9272", "#fb6a4a", "#ef3b2c", "#cb181d", "#a50f15", "#67000d")) + theme_classic(8) + ylab("Proportion of votes for invasive phenotype") + xlab("Model iteration") + geom_hline(yintercept=0.5, lty=2, col="grey") + theme(legend.key.size = unit(0.3, "cm"))
ggsave("full_votes.png", width=7, height=2.5)
ggsave("full_votes.pdf", width=7, height=2.5)

```


```{r, assessing stability of predictors}
set.seed(1)

usefulgenes <- data.frame()
topgenes <- data.frame()

for(i in 1:10) {
  model <- randomForest(class ~ ., data=traineggNOG, ntree=10000, mtry=param/10, na.action=na.roughfix)
  usefulgenes <- rbind(usefulgenes, cbind(model=i, gene=names(model$importance[model$importance>0,]), model$importance[model$importance>0]))
  topgenes <- rbind(topgenes, cbind(model=i, gene=names(model$importance[order(model$importance, decreasing=T),][1:20]), model$importance[order(model$importance, decreasing=T),][1:20]))
}

png("gene_usefulness.png")
hist(table(usefulgenes$gene), col="grey", main="", xlab="Number of times each gene was useful in a model")
dev.off()
sum(table(usefulgenes$gene)==10)
sum(table(usefulgenes$gene)<10)

topgenes$V3 <- as.numeric(as.character(topgenes$V3))

topgenes2 <- data.frame()
for(i in 1:10) {
  topgenes2 <- rbind(topgenes2, topgenes[topgenes$model==i & topgenes$V3>quantile(topgenes$V3[topgenes$model==i], 0.5),])
}

ggplot(topgenes, aes(x=model, y=gene, fill=as.numeric(V3))) + geom_tile()
ggplot(topgenes2, aes(x=model, y=gene, fill=as.numeric(V3))) + geom_tile()

table(topgenes$gene)
png("topgenes.png")
hist(table(topgenes$gene), col="grey", main="", xlab="Number of times each gene appeared in the\ntop 20 predictors")
dev.off()

save(usefulgenes, topgenes, file="allgenemodels_10x.Rdata")
```


```{r, plot scores for top indicators}
library(reshape)

scoresdata <- melt(cbind.data.frame(strain=row.names(train5), class=train5$class, t(eggNOG2[match(colnames(train5), row.names(eggNOG2)),])))

ggplot(scoresdata, aes(y=variable, x=factor(strain, levels=row.names(train5)), fill=value)) + geom_tile() + scale_fill_gradientn(colours=c("blue", "white", "red"), values=c(0,0.28,1))
ggplot(scoresdata, aes(x=value)) + geom_histogram() + facet_wrap(class~strain, ncol=7) + theme_classic() + ylab("Delta-bitscore") + xlab("Frequency")

# trimmed further

scoresdata2 <- scoresdata[scoresdata$variable %in% names(model$importance[order(model$importance, decreasing=T),])[1:50],]
ggplot(scoresdata2, aes(y=variable, x=factor(strain, levels=row.names(train3)), fill=value)) + geom_tile() + scale_fill_gradientn(colours=c("blue", "white", "red"), values=c(0,0.15,1))

ggplot(scoresdata2, aes(x=value, y=variable, col=factor(class, levels=c("Invasive", "Gastro")))) + geom_jitter(height=0.3) + xlim(-7,14) + theme_classic()

rows <- vector()
bigtree <- data.frame()
for(i in 1:2000) {
  rows <- c(rows, nrow(getTree(model, i)))
  if(nrow(getTree(model, i))>3) {
    bigtree <- rbind.data.frame(bigtree, cbind.data.frame(variables=getTree(model, i)[,3], tree=rep(i, nrow(getTree(model, i)))))
  }
}
```

```{r, compare to univariate tests}
coefficients <- vector()
pvals <- vector()
ks <- vector()
ksp <- vector()
mwu <- vector()
mwup <- vector()

for(i in colnames(traineggNOG)) {
  if (i == "class") {
    pvals <- c(pvals, NA)
    coefficients <- c(coefficients, NA)
    ks <- c(ks, NA)
    ksp <- c(ksp, NA)
    mwu <- c(mwu, NA)
    mwup <- c(mwup, NA)
  } else {
    test <- summary(lm(as.numeric(class)~get(i), data=traineggNOG))
    pvals <- c(pvals, test$coefficients[2,4])
    coefficients <- c(coefficients, test$coefficients[2,1])
      kstest <- ks.test(traineggNOG[,i][traineggNOG$class=="Invasive"], traineggNOG[,i][traineggNOG$class=="Gastro"])
      ks <- c(ks, kstest$statistic)
      ksp <- c(ksp, kstest$p.value)
      mwutest <- wilcox.test(traineggNOG[,i][traineggNOG$class=="Invasive"], traineggNOG[,i][traineggNOG$class=="Gastro"], paired=F)
      mwu <- c(mwu, mwutest$statistic)
      mwup <- c(mwup, mwutest$p.value)
  }
}

locations <- match(names(train5)[-ncol(train5)], names(traineggNOG))

hist(mwu)

sum(pvals[locations]<0.05, na.rm=T)
sum(ksp[locations]<0.05, na.rm=TRUE)
sum(mwup[locations]<0.05, na.rm=TRUE)
sum(mwup[locations]<0.05&mwu[locations]>21, na.rm=TRUE)
sum(mwup[locations]<0.05&mwu[locations]<21, na.rm=TRUE)

png("lm_pvals_models.png", width=450, height=325)
hist(pvals, breaks=50, main="", xlab="Nominal P-values")
hist(pvals[locations], add=T, col=rgb(1,0,0,0.5), breaks=50)
legend("topright", legend=c("All genes", "196 genes from final model"), fill=c("white", rgb(1,0,0,0.7)))
dev.off()
# excess of certain p-value, corresponding to different numbers of missing genes

png("ks_pvals_models.png", width=450, height=325)
hist(ksp, breaks=25, main="", xlab="Kolmogorov-Smirnov nominal P-values")
hist(ksp[locations], add=T, col=rgb(1,0,0,0.5), breaks=3)
legend("topright", legend=c("All genes", "196 genes from final model"), fill=c("white", rgb(1,0,0,0.7)))
dev.off()

png("mwu_pvals_models.png", width=450, height=325)
hist(mwup, breaks=50, main="", xlab="Mann Whitney U nominal P-values")
hist(mwup[locations], add=T, col=rgb(1,0,0,0.5), breaks=20)
legend("topright", legend=c("All genes", "196 genes from final model"), fill=c("white", rgb(1,0,0,0.7)))
dev.off()

toppvals <- match(pvals[locations][pvals[locations]>0.4], pvals[locations])
columns <- locations[toppvals]
boxplot(traineggNOG[,columns[1]]~traineggNOG$class)

toppvals <- match(ksp[locations][ksp[locations]>0.1], ksp[locations])
columns <- locations[toppvals]
boxplot(traineggNOG[,columns[1]]~traineggNOG$class)

columns <- locations[mwup[locations]<0.05&mwu[locations]>21]
names(traineggNOG)[columns]

save(pvals, coefficients, ks, ksp, mwu, mwup, file="association_tests.Rdata")
load("association_tests.Rdata")
```


```{r, COG analysis}
indicators <- names(train5)[-ncol(train5)]
genes <- sub("_.*", "", indicators)
nogs <- sub(".*_gproNOG.", "", indicators)
nogs <- sub(".meta_raw", "", nogs)

annotations <- read.delim("gproNOG.annotations.tsv", header=F)  # can be downloaded from http://eggnogdb.embl.de/#/app/downloads
info <- annotations[match(nogs, annotations[,2]),]
info$V5 <- as.character(info$V5)

# proportion of each COG catergory that comes up in the top indicators
background <- colnames(traineggNOG)
background <- sub(".*_gproNOG.", "", background)
background <- sub(".meta_raw", "", background)
background_COGs <- annotations[match(background, annotations[,2]),5]
background_COGs2 <- vector()
for(i in background_COGs) {
    if(!is.na(i)) {
       if(nchar(i)>1) {
        for(n in 1:nchar(i)) {
          background_COGs2 <- c(background_COGs2, substr(i,n,n))
        }
      } else {
    background_COGs2 <- rbind(background_COGs2, i)
  }
  }
}

predictor_COGs <- data.frame()
for(i in 1:nrow(info)) {
  if(!is.na(info$V5[i])) {
       if(nchar(info$V5[i])>1) {
    for(n in 1:nchar(info$V5[i])) {
      line <- info[i,]
      line$V5 <- substr(info$V5[i],n,n)
      predictor_COGs <- rbind(predictor_COGs, line)
    }
  } else {
    predictor_COGs <- rbind(predictor_COGs, info[i,])
  }

  }
 }
table(info[,5])/table(annotations[,5])[match(names(table(info[,5])), names(table(annotations[,5])))]

```


```{r, control}
set.seed(1)

control <- traineggNOG2
control$class <- sample(traineggNOG2$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=control, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/4415)
}
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=sparsity)

png("control_error_vs_ntree.png", width=350, height = 350)
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error, xlab="Number of trees", ylab="Median OOB error rate", pch=16)
dev.off()

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 44, 1000, 2208, 3000, 3742)) {
  model <- randomForest(class ~ ., data=control, ntree=1000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/3742)
}
plot(x=c(1, 44, 1000, 2208, 3000, 3742), y=error2)
plot(x=c(1, 44, 1000, 2208, 3000, 3742), y=sparsity2)

png("control_sparsity_vs_mtry.png", width=350, height = 350)
plot(x=c(1, 44, 1000, 2000, 3000, 4415), y=sparsity2, xlab="Number of genes sampled per tree", ylab="% genes uninformative", pch=16)
dev.off()

ctrain2 <- control[,match(names(model$importance[model$importance[,1]>0,]), colnames(control))]
ctrain2 <- cbind(ctrain2, class=control$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=ctrain2, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(ctrain2)-1))
}
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error)

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 10, 50, 100, 200, 300, 400, 441)) {
  model <- randomForest(class ~ ., data=ctrain2, ntree=20000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(ctrain2)-1))
}
plot(x=c(1, 10, 50, 100, 200, 300, 400, 441), y=error2)
plot(x=c(1, 10, 50, 100, 200, 300, 400, 441), y=sparsity2)

ctrain3 <- ctrain2[,match(names(model$importance[model$importance[,1]>quantile(model$importance[,1], 0.5),]), colnames(ctrain2))]
ctrain3 <- cbind(ctrain3, class=ctrain2$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=ctrain3, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(ctrain2)-1))
}
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error)

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 2, 10, 50, 100, 200, 239)) {
  model <- randomForest(class ~ ., data=ctrain3, ntree=2000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(ctrain3)-1))
}
plot(x=c(1, 2, 10, 50, 100, 200, 250), y=error2)
plot(x=c(1, 10, 50, 100, 200, 250), y=sparsity2)

ctrain4 <- ctrain3[,match(names(model$importance[model$importance[,1]>quantile(model$importance[,1], 0.5),]), colnames(ctrain3))]
ctrain4 <- cbind(ctrain4, class=ctrain3$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=ctrain4, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(ctrain4)-1))
}
plot(x=c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000), y=error)

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 2, 10, 50, 100, 110)) {
  model <- randomForest(class ~ ., data=ctrain4, ntree=5000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(ctrain4)-1))
}
plot(x=c(1, 2, 10, 50, 100, 110), y=error2)
plot(x=c(1, 2, 10, 50, 100, 110), y=sparsity2)


cmodel <- randomForest(class ~ ., data=ctrain4, ntree=10000, mtry=10, na.action=na.roughfix)

save(cmodel, ctrain2, ctrain3, ctrain4, file="control_traindata.Rdata")

```

```{r, testing the robustness of the top result}
topgenes <- vector()

# picking out the top predictors from the model
for(i in 1:5) {
  set.seed(i)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=traineggNOG, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(traineggNOG)-1))
}

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 44, 1000, 2208, 3000, 3742)) {
  model <- randomForest(class ~ ., data=traineggNOG, ntree=1000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(traineggNOG)-1))
}

train2 <- traineggNOG[,match(names(model$importance[model$importance[,1]>0,]), colnames(traineggNOG))]
train2 <- cbind(train2, class=traineggNOG$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=train2, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(train2)-1))
}

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 10, 50, 100, 200, 300, 400, 441)) {
  model <- randomForest(class ~ ., data=train2, ntree=20000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(train2)-1))
}

train3 <- train2[,match(names(model$importance[model$importance[,1]>quantile(model$importance[,1], 0.5),]), colnames(train2))]
train3 <- cbind(train3, class=train2$class)

error <- vector()
sparsity <- vector()
for(i in c(1, 10, 50, 250, 500, 1000, 1500, 2000, 5000, 10000)) {
  model <- randomForest(class ~ ., data=train3, ntree=i, na.action=na.roughfix)
  error <- c(error, median(model$err.rate))
  sparsity <- c(sparsity, (sum(model$importance[,1]<=0))/(ncol(train3)-1))
}

error2 <- vector()
sparsity2 <- vector()
for(i in c(1, 2, 10, 50, 100, 200, 239)) {
  model <- randomForest(class ~ ., data=train3, ntree=2000, mtry=i, na.action=na.roughfix)
  error2 <- c(error2, median(model$err.rate))
  sparsity2 <- c(sparsity2, (sum(model$importance[,1]<=0))/(ncol(train3)-1))
}

train4 <- train3[,match(names(model$importance[model$importance[,1]>quantile(model$importance[,1], 0.5),]), colnames(train3))]
train4 <- cbind(train4, class=train3$class)

topgenes <- c(topgenes, colnames(train4))
}

```

